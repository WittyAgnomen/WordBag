{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "This notebook is designed to be an introduction for creating your own bag of words function with Python; or simply put, creating a fuction to count word frequinces in some string or document. The notebook will also cover some useful add-on fuctions for bag of words like remove stop words and keep the n-most frequent words from a bag. Note: Worded explanations are sparse in this notebook because the code is rather straight foward. If you want more insight, just check out the <a href=\"https://en.wikipedia.org/wiki/Bag-of-words_model\">wiki page</a>.\n",
    "\n",
    "## Counting Words in a String\n",
    "\n",
    "To begin, let's split a string into a list of its components and count the frequency of each of the words in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr obama acknowledged that the killings  an act not just of demented violence but of racial hatred  had exposed a fault line in american democracy he said he understood if americans questioned whether the racial divide would ever be bridged\n",
      "[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#the string we wish to count over\n",
    "somewords=\"Mr. Obama acknowledged that the killings - an act not just of demented violence but of racial hatred - had exposed a fault line in American democracy. He said he understood if Americans questioned whether the racial divide would ever be bridged.\"\n",
    "\n",
    "#strip puncuations and transform to lower case\n",
    "import string\n",
    "somewords=somewords.translate(string.maketrans(\"\",\"\"), string.punctuation).lower()\n",
    "\n",
    "#split string into list of words\n",
    "wordlist=somewords.split()\n",
    "\n",
    "#get word count for every word in list\n",
    "wordcount= [wordlist.count(word) for word in wordlist]\n",
    "    \n",
    "print somewords\n",
    "print wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping into a Dictionary and Making as a Function\n",
    "\n",
    "Now that we have counted the amount times a word appears in the string, let's put it into a dictionary (hash). By doing this, the duplicates we saw above will go away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary with word count\n",
    "def WordBag(aString):\n",
    "    wordlist=aString.translate(string.maketrans(\"\",\"\"), string.punctuation).lower().split()\n",
    "    wordcount = [wordlist.count(word) for word in wordlist]\n",
    "    return dict(zip(wordlist,wordcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'divide': 1, 'just': 1, 'exposed': 1, 'an': 1, 'understood': 1, 'demented': 1, 'americans': 1, 'in': 1, 'racial': 2, 'if': 1, 'killings': 1, 'democracy': 1, 'had': 1, 'questioned': 1, 'bridged': 1, 'he': 2, 'ever': 1, 'be': 1, 'that': 1, 'mr': 1, 'but': 1, 'said': 1, 'not': 1, 'line': 1, 'the': 2, 'obama': 1, 'a': 1, 'would': 1, 'whether': 1, 'of': 2, 'violence': 1, 'acknowledged': 1, 'american': 1, 'act': 1, 'hatred': 1, 'fault': 1}\n"
     ]
    }
   ],
   "source": [
    "#test it on somewords\n",
    "test=WordBag(somewords)\n",
    "\n",
    "print test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to add Ordering\n",
    "\n",
    "Yes, it is that simple. Now, we have one of the most basic tools for investigating text in machine learning. Let's add some extras. \n",
    "\n",
    "The first extra is just a simple function to order the bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create ordering function, note: will always order words in alphabetical order\n",
    "def OrderWordBag(bag, Descending=True):\n",
    "    arr=[(bag[key], key) for key in bag]\n",
    "    if Descending==True:\n",
    "        return sorted(arr, key=lambda x: (-x[0], x[1]))\n",
    "    else:\n",
    "        return sorted(arr, key=lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'he'), (2, 'of'), (2, 'racial'), (2, 'the'), (1, 'a'), (1, 'acknowledged'), (1, 'act'), (1, 'american'), (1, 'americans'), (1, 'an'), (1, 'be'), (1, 'bridged'), (1, 'but'), (1, 'demented'), (1, 'democracy'), (1, 'divide'), (1, 'ever'), (1, 'exposed'), (1, 'fault'), (1, 'had'), (1, 'hatred'), (1, 'if'), (1, 'in'), (1, 'just'), (1, 'killings'), (1, 'line'), (1, 'mr'), (1, 'not'), (1, 'obama'), (1, 'questioned'), (1, 'said'), (1, 'that'), (1, 'understood'), (1, 'violence'), (1, 'whether'), (1, 'would')]\n"
     ]
    }
   ],
   "source": [
    "#order descending\n",
    "print OrderWordBag(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (1, 'acknowledged'), (1, 'act'), (1, 'american'), (1, 'americans'), (1, 'an'), (1, 'be'), (1, 'bridged'), (1, 'but'), (1, 'demented'), (1, 'democracy'), (1, 'divide'), (1, 'ever'), (1, 'exposed'), (1, 'fault'), (1, 'had'), (1, 'hatred'), (1, 'if'), (1, 'in'), (1, 'just'), (1, 'killings'), (1, 'line'), (1, 'mr'), (1, 'not'), (1, 'obama'), (1, 'questioned'), (1, 'said'), (1, 'that'), (1, 'understood'), (1, 'violence'), (1, 'whether'), (1, 'would'), (2, 'he'), (2, 'of'), (2, 'racial'), (2, 'the')]\n"
     ]
    }
   ],
   "source": [
    "#order ascending\n",
    "print OrderWordBag(test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to take n-top words\n",
    "\n",
    "The second extra arises when we only care about the most seen words. We can write a function that takes the output from our bag of words function and just keeps the  n most seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to take the n most counted words, \n",
    "#note: a_to_z is the alphabetical ordering or the reverses\n",
    "def ntop(n,bag,a_to_z=True):\n",
    "    arr=[(bag[key], key) for key in bag]\n",
    "    if a_to_z==True:\n",
    "        return sorted(arr, key=lambda x: (-x[0], x[1]))[0:n]\n",
    "    else:\n",
    "        return sorted(arr, key=lambda x: (x[0], x[1]), reverse=True)[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'he'), (2, 'of'), (2, 'racial'), (2, 'the'), (1, 'a'), (1, 'acknowledged'), (1, 'act'), (1, 'american')]\n"
     ]
    }
   ],
   "source": [
    "#8 top counted, a to z ordering\n",
    "print ntop(8,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'the'), (2, 'racial'), (2, 'of'), (2, 'he'), (1, 'would'), (1, 'whether'), (1, 'violence'), (1, 'understood')]\n"
     ]
    }
   ],
   "source": [
    "#8 top counted, z to a ordering\n",
    "print ntop(8,test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Function to Remove Stop Words\n",
    "\n",
    "The last add on is removing 'stop words'. Stop words are words that apear in all documents and the thought is, because of this, add no real value to saying something about a document. These are words like: the, a ,are, is, it, etc. Below we create a list of stop words, a function to remove them, and run the function on a complete article we read in to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DALLAS - President Obama said on Tuesday that the nation mourned along with Dallas for five police officers gunned down by a black Army veteran, but he implored Americans not to give in to despair or the fear that the center might not hold.Im here to say that we must reject such despair, Mr. Obama said at a memorial service for the officers in Dallas. Im here to insist that we are not so divided as we seem. I say that because I know America. I know how far weve come against impossible odds. I know well make it because of what Ive experienced in my own life.Mr. Obama acknowledged that the killings - an act not just of demented violence but of racial hatred - had exposed a fault line in American democracy. He said he understood if Americans questioned whether the racial divide would ever be bridged.Im not nave, he said. Ive spoken at too many memorials during the course of this presidency.Mr. Obama acknowledged the limitations of his own words, and quoted from the Gospel of John: Let us love not with words or speech but with action and in truth.Mr. Obama, as he has before, balanced praise for the heroism of police officers with a blunt acknowledgment of racial bias in the criminal justice system. We cant simply dismiss it as a symptom of political correctness or reverse racism, he said.Behind him, a row of police officers did not clap. But when Mr. Obama added, We ask the police to do too much, and we ask too little of ourselves, the officers behind him applauded.The president appealed for an honest debate over the tensions inherent in policing and the nations legacy of racism. It is forging consensus, and fighting cynicism, and finding the will to make change, he said.I confess that sometimes, too, I experience doubt, Mr. Obama said. Ive been to too many of these things. Ive seen too many families go through this.Former President George W. Bush spoke earlier at the memorial. Today the nation grieves, but those of us who love Dallas and call it home have had five deaths in the family, Mr. Bush said. He added, At times it seems like the forces pulling us apart are stronger than the forces binding us together.But, Mr. Bush said, Americans, I think, have a great advantage. To renew our unity we only have to remember our values.Mr. Obama had huddled with his speechwriters for much of Monday, hoping to find words that would not only console the officers grief-stricken families but also reassure a nation fearful that racial divisions are worsening after the Dallas slaughter and the killing days before of black men by the police in Louisiana and Minnesota.Mr. Obama approached the effort with the frustration of a man who has poured his heart and soul into similar speeches, only to later feel that nothing has changed and no one is listening. This was the 11th time in his presidency that he sought to comfort a city after a mass killing, and the second time in a month that such a killing grew out of bias.The president recognizes that its not just people in Dallas who are grieving, its people all across the country who are concerned about the violence that so many Americans have witnessed in the last week or so, Josh Earnest, the White House press secretary, said on Monday.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read an article into a string variable, and remove ugly encodings\n",
    "with open (\"ObamaArticle.txt\", \"r\") as myfile:\n",
    "    article=myfile.read().decode('utf-8')\n",
    "    article=article.replace(u'\\u201d','').replace(u'\\n','').replace(u'\\u2019','')\n",
    "    article=article.replace(u'\\u201c','').replace(u'\\u2019m','')\n",
    "    article=article.encode('ascii', 'ignore')\n",
    "    \n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 1, 'bush': 3, 'listening': 1, 'just': 2, 'huddled': 1, 'over': 1, 'people': 2, 'thisformer': 1, 'month': 1, 'course': 1, 'through': 1, 'saidbehind': 1, 'go': 1, 'love': 2, 'fear': 1, 'debate': 1, 'before': 2, 'fearful': 1, 'killings': 1, 'police': 5, 'quoted': 1, 'comfort': 1, 'also': 1, 'justice': 1, 'truthmr': 1, 'concerned': 1, 'remember': 1, 'had': 3, 'about': 1, 'to': 12, 'heroism': 1, 'black': 2, 'questioned': 1, 'he': 9, 'might': 1, 'into': 1, 'divided': 1, 'do': 1, 'weve': 1, 'advantage': 1, 'far': 1, 'similar': 1, 'later': 1, 'saidi': 1, 'nation': 3, 'earnest': 1, 'grew': 1, 'five': 2, 'know': 3, 'words': 3, 'not': 9, 'during': 1, 'one': 1, 'him': 2, 'apart': 1, 'worsening': 1, 'like': 1, 'did': 1, 'across': 1, 'consensus': 1, 'this': 2, 'changed': 1, 'holdim': 1, 'simply': 1, 'gospel': 1, 'fault': 1, 'out': 1, 'clap': 1, 'secretary': 1, 'because': 2, 'nave': 1, 'exposed': 1, 'house': 1, 'cynicism': 1, 'stronger': 1, 'feel': 1, 'soul': 1, 'understood': 1, 'demented': 1, 'added': 2, 'are': 5, 'forging': 1, 'cant': 1, 'home': 1, 'racial': 4, 'ourselves': 1, 'after': 2, 'seems': 1, 'what': 1, 'said': 8, 'acknowledgment': 1, 'for': 5, 'griefstricken': 1, 'tensions': 1, 'confess': 1, 'effort': 1, 'find': 1, 'behind': 1, 'experience': 1, 'row': 1, 'ever': 1, 'grieves': 1, 'limitations': 1, 'be': 1, 'we': 7, 'who': 4, 'approached': 1, 'doubt': 1, 'bridgedim': 1, 'men': 1, 'here': 2, 'killing': 3, 'white': 1, 'let': 1, 'slaughter': 1, 'inherent': 1, 'ask': 2, 'console': 1, 'along': 1, 'come': 1, 'by': 2, 'change': 1, 'on': 2, 'great': 1, 'last': 1, 'would': 2, 'renew': 1, 'of': 18, 'violence': 2, 'correctness': 1, 'days': 1, 'against': 1, 'honest': 1, 'american': 1, 'despair': 2, 'w': 1, 'act': 1, 'action': 1, 'recognizes': 1, 'hatred': 1, 'grieving': 1, 'or': 4, 'mass': 1, 'own': 2, 'memorials': 1, 'divide': 1, 'family': 1, 'heart': 1, 'spoken': 1, 'lifemr': 1, 'tuesday': 1, 'reassure': 1, 'insist': 1, 'racism': 2, 'down': 1, 'americans': 4, 'such': 2, 'balanced': 1, 'impossible': 1, 'george': 1, 'second': 1, 'city': 1, 'little': 1, 'from': 1, 'spoke': 1, 'service': 1, 'army': 1, 'deaths': 1, 'political': 1, 'system': 1, 'been': 1, 'much': 2, 'call': 1, 'too': 6, 'frustration': 1, 'minnesotamr': 1, 'john': 1, 'louisiana': 1, 'today': 1, 'only': 3, 'families': 2, 'press': 1, 'that': 14, 'dismiss': 1, 'speeches': 1, 'but': 6, 'valuesmr': 1, 'line': 1, 'with': 6, 'than': 1, 'symptom': 1, 'must': 1, 'divisions': 1, 'has': 3, 'legacy': 1, 'josh': 1, 'presidency': 1, 'whether': 1, 'was': 1, 'as': 3, 'us': 4, 'nations': 1, 'will': 1, 'bias': 1, 'those': 1, 'praise': 1, 'mr': 5, 'pulling': 1, 'country': 1, 'my': 1, 'and': 12, 'ive': 4, 'policing': 1, 'reverse': 1, 'hoping': 1, 'give': 1, 'well': 1, 'is': 2, 'binding': 1, 'it': 5, 'an': 2, 'applaudedthe': 1, 'say': 2, 'his': 4, 'im': 1, 'at': 4, 'have': 4, 'in': 13, 'sought': 1, 'seen': 1, 'seem': 1, 'times': 1, '11th': 1, 'if': 1, 'these': 1, 'memorial': 2, 'democracy': 1, 'dallas': 6, 'things': 1, 'make': 2, 'speechwriters': 1, 'when': 1, 'officers': 6, 'togetherbut': 1, 'how': 1, 'unity': 1, 'speech': 1, 'forces': 2, 'reject': 1, 'finding': 1, 'gunned': 1, 'many': 4, 'blunt': 1, 'witnessed': 1, 'week': 1, 'criminal': 1, 'obama': 9, 'experienced': 1, 'presidencymr': 1, 'monday': 2, 'our': 2, 'earlier': 1, 'implored': 1, 'nothing': 1, 'president': 4, 'appealed': 1, 'america': 1, 'man': 1, 'a': 13, 'mourned': 1, 'no': 1, 'center': 1, 'i': 6, 'odds': 1, 'sometimes': 1, 'acknowledged': 2, 'fighting': 1, 'think': 1, 'biasthe': 1, 'so': 3, 'poured': 1, 'time': 2, 'the': 33, 'its': 2, 'veteran': 1}\n"
     ]
    }
   ],
   "source": [
    "art=WordBag(article)\n",
    "\n",
    "print art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(33, 'the'), (18, 'of'), (14, 'that'), (13, 'a'), (13, 'in'), (12, 'and'), (12, 'to'), (9, 'he'), (9, 'not'), (9, 'obama'), (8, 'said'), (7, 'we'), (6, 'but'), (6, 'dallas'), (6, 'i'), (6, 'officers'), (6, 'too'), (6, 'with'), (5, 'are'), (5, 'for'), (5, 'it'), (5, 'mr'), (5, 'police'), (4, 'americans'), (4, 'at'), (4, 'have'), (4, 'his'), (4, 'ive'), (4, 'many'), (4, 'or'), (4, 'president'), (4, 'racial'), (4, 'us'), (4, 'who'), (3, 'as'), (3, 'bush'), (3, 'had'), (3, 'has'), (3, 'killing'), (3, 'know'), (3, 'nation'), (3, 'only'), (3, 'so'), (3, 'words'), (2, 'acknowledged'), (2, 'added'), (2, 'after'), (2, 'an'), (2, 'ask'), (2, 'because'), (2, 'before'), (2, 'black'), (2, 'by'), (2, 'despair'), (2, 'families'), (2, 'five'), (2, 'forces'), (2, 'here'), (2, 'him'), (2, 'is'), (2, 'its'), (2, 'just'), (2, 'love'), (2, 'make'), (2, 'memorial'), (2, 'monday'), (2, 'much'), (2, 'on'), (2, 'our'), (2, 'own'), (2, 'people'), (2, 'racism'), (2, 'say'), (2, 'such'), (2, 'this'), (2, 'time'), (2, 'violence'), (2, 'would'), (1, '11th'), (1, 'about'), (1, 'acknowledgment'), (1, 'across'), (1, 'act'), (1, 'action'), (1, 'advantage'), (1, 'against'), (1, 'all'), (1, 'along'), (1, 'also'), (1, 'america'), (1, 'american'), (1, 'apart'), (1, 'appealed'), (1, 'applaudedthe'), (1, 'approached'), (1, 'army'), (1, 'balanced'), (1, 'be'), (1, 'been'), (1, 'behind'), (1, 'bias'), (1, 'biasthe'), (1, 'binding'), (1, 'blunt'), (1, 'bridgedim'), (1, 'call'), (1, 'cant'), (1, 'center'), (1, 'change'), (1, 'changed'), (1, 'city'), (1, 'clap'), (1, 'come'), (1, 'comfort'), (1, 'concerned'), (1, 'confess'), (1, 'consensus'), (1, 'console'), (1, 'correctness'), (1, 'country'), (1, 'course'), (1, 'criminal'), (1, 'cynicism'), (1, 'days'), (1, 'deaths'), (1, 'debate'), (1, 'demented'), (1, 'democracy'), (1, 'did'), (1, 'dismiss'), (1, 'divide'), (1, 'divided'), (1, 'divisions'), (1, 'do'), (1, 'doubt'), (1, 'down'), (1, 'during'), (1, 'earlier'), (1, 'earnest'), (1, 'effort'), (1, 'ever'), (1, 'experience'), (1, 'experienced'), (1, 'exposed'), (1, 'family'), (1, 'far'), (1, 'fault'), (1, 'fear'), (1, 'fearful'), (1, 'feel'), (1, 'fighting'), (1, 'find'), (1, 'finding'), (1, 'forging'), (1, 'from'), (1, 'frustration'), (1, 'george'), (1, 'give'), (1, 'go'), (1, 'gospel'), (1, 'great'), (1, 'grew'), (1, 'griefstricken'), (1, 'grieves'), (1, 'grieving'), (1, 'gunned'), (1, 'hatred'), (1, 'heart'), (1, 'heroism'), (1, 'holdim'), (1, 'home'), (1, 'honest'), (1, 'hoping'), (1, 'house'), (1, 'how'), (1, 'huddled'), (1, 'if'), (1, 'im'), (1, 'implored'), (1, 'impossible'), (1, 'inherent'), (1, 'insist'), (1, 'into'), (1, 'john'), (1, 'josh'), (1, 'justice'), (1, 'killings'), (1, 'last'), (1, 'later'), (1, 'legacy'), (1, 'let'), (1, 'lifemr'), (1, 'like'), (1, 'limitations'), (1, 'line'), (1, 'listening'), (1, 'little'), (1, 'louisiana'), (1, 'man'), (1, 'mass'), (1, 'memorials'), (1, 'men'), (1, 'might'), (1, 'minnesotamr'), (1, 'month'), (1, 'mourned'), (1, 'must'), (1, 'my'), (1, 'nations'), (1, 'nave'), (1, 'no'), (1, 'nothing'), (1, 'odds'), (1, 'one'), (1, 'ourselves'), (1, 'out'), (1, 'over'), (1, 'policing'), (1, 'political'), (1, 'poured'), (1, 'praise'), (1, 'presidency'), (1, 'presidencymr'), (1, 'press'), (1, 'pulling'), (1, 'questioned'), (1, 'quoted'), (1, 'reassure'), (1, 'recognizes'), (1, 'reject'), (1, 'remember'), (1, 'renew'), (1, 'reverse'), (1, 'row'), (1, 'saidbehind'), (1, 'saidi'), (1, 'second'), (1, 'secretary'), (1, 'seem'), (1, 'seems'), (1, 'seen'), (1, 'service'), (1, 'similar'), (1, 'simply'), (1, 'slaughter'), (1, 'sometimes'), (1, 'sought'), (1, 'soul'), (1, 'speech'), (1, 'speeches'), (1, 'speechwriters'), (1, 'spoke'), (1, 'spoken'), (1, 'stronger'), (1, 'symptom'), (1, 'system'), (1, 'tensions'), (1, 'than'), (1, 'these'), (1, 'things'), (1, 'think'), (1, 'thisformer'), (1, 'those'), (1, 'through'), (1, 'times'), (1, 'today'), (1, 'togetherbut'), (1, 'truthmr'), (1, 'tuesday'), (1, 'understood'), (1, 'unity'), (1, 'valuesmr'), (1, 'veteran'), (1, 'w'), (1, 'was'), (1, 'week'), (1, 'well'), (1, 'weve'), (1, 'what'), (1, 'when'), (1, 'whether'), (1, 'white'), (1, 'will'), (1, 'witnessed'), (1, 'worsening')]\n"
     ]
    }
   ],
   "source": [
    "#order descending\n",
    "print OrderWordBag(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array holding the words we would like to remove\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "stopwords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "stopwords += ['yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a dict of words, remove any that are\n",
    "# in a list of stop words.\n",
    "\n",
    "def removeStopwords(bag, stopwords):\n",
    "    for s in stopwords:\n",
    "        if s in bag.keys():\n",
    "            del bag[s]      \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bush': 3, 'listening': 1, 'just': 2, 'huddled': 1, 'people': 2, 'thisformer': 1, 'month': 1, 'course': 1, 'saidbehind': 1, 'love': 2, 'fear': 1, 'debate': 1, 'fearful': 1, 'killings': 1, 'police': 5, 'quoted': 1, 'comfort': 1, 'justice': 1, 'truthmr': 1, 'concerned': 1, 'remember': 1, 'heroism': 1, 'black': 2, 'questioned': 1, 'divided': 1, 'weve': 1, 'advantage': 1, 'far': 1, 'similar': 1, 'later': 1, 'saidi': 1, 'nation': 3, 'earnest': 1, 'grew': 1, 'know': 3, 'words': 3, 'apart': 1, 'worsening': 1, 'like': 1, 'consensus': 1, 'changed': 1, 'holdim': 1, 'simply': 1, 'gospel': 1, 'fault': 1, 'clap': 1, 'secretary': 1, 'nave': 1, 'exposed': 1, 'house': 1, 'cynicism': 1, 'stronger': 1, 'feel': 1, 'soul': 1, 'understood': 1, 'demented': 1, 'added': 2, 'forging': 1, 'home': 1, 'racial': 4, 'said': 8, 'acknowledgment': 1, 'griefstricken': 1, 'tensions': 1, 'confess': 1, 'effort': 1, 'experience': 1, 'row': 1, 'grieves': 1, 'limitations': 1, 'approached': 1, 'doubt': 1, 'bridgedim': 1, 'men': 1, 'killing': 3, 'white': 1, 'let': 1, 'slaughter': 1, 'inherent': 1, 'ask': 2, 'console': 1, 'come': 1, 'change': 1, 'great': 1, 'renew': 1, 'violence': 2, 'correctness': 1, 'days': 1, 'honest': 1, 'american': 1, 'despair': 2, 'w': 1, 'act': 1, 'action': 1, 'recognizes': 1, 'hatred': 1, 'grieving': 1, 'mass': 1, 'memorials': 1, 'divide': 1, 'family': 1, 'heart': 1, 'spoken': 1, 'lifemr': 1, 'tuesday': 1, 'reassure': 1, 'insist': 1, 'racism': 2, 'americans': 4, 'balanced': 1, 'impossible': 1, 'george': 1, 'second': 1, 'city': 1, 'little': 1, 'spoke': 1, 'service': 1, 'army': 1, 'deaths': 1, 'political': 1, 'frustration': 1, 'minnesotamr': 1, 'john': 1, 'louisiana': 1, 'today': 1, 'families': 2, 'press': 1, 'dismiss': 1, 'speeches': 1, 'valuesmr': 1, 'line': 1, 'symptom': 1, 'divisions': 1, 'legacy': 1, 'josh': 1, 'presidency': 1, 'nations': 1, 'bias': 1, 'praise': 1, 'mr': 5, 'pulling': 1, 'country': 1, 'ive': 4, 'policing': 1, 'reverse': 1, 'hoping': 1, 'binding': 1, 'applaudedthe': 1, 'say': 2, 'im': 1, 'sought': 1, 'seen': 1, 'times': 1, '11th': 1, 'memorial': 2, 'democracy': 1, 'dallas': 6, 'things': 1, 'make': 2, 'speechwriters': 1, 'officers': 6, 'togetherbut': 1, 'unity': 1, 'speech': 1, 'forces': 2, 'reject': 1, 'finding': 1, 'gunned': 1, 'blunt': 1, 'witnessed': 1, 'week': 1, 'criminal': 1, 'obama': 9, 'experienced': 1, 'presidencymr': 1, 'monday': 2, 'earlier': 1, 'implored': 1, 'president': 4, 'appealed': 1, 'america': 1, 'man': 1, 'mourned': 1, 'center': 1, 'odds': 1, 'acknowledged': 2, 'fighting': 1, 'think': 1, 'biasthe': 1, 'poured': 1, 'time': 2, 'veteran': 1}\n"
     ]
    }
   ],
   "source": [
    "print removeStopwords(art, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 'obama'), (8, 'said'), (6, 'dallas'), (6, 'officers'), (5, 'mr'), (5, 'police'), (4, 'americans'), (4, 'ive'), (4, 'president'), (4, 'racial'), (3, 'bush'), (3, 'killing'), (3, 'know'), (3, 'nation'), (3, 'words'), (2, 'acknowledged'), (2, 'added'), (2, 'ask'), (2, 'black'), (2, 'despair'), (2, 'families'), (2, 'forces'), (2, 'just'), (2, 'love'), (2, 'make'), (2, 'memorial'), (2, 'monday'), (2, 'people'), (2, 'racism'), (2, 'say'), (2, 'time'), (2, 'violence'), (1, '11th'), (1, 'acknowledgment'), (1, 'act'), (1, 'action'), (1, 'advantage'), (1, 'america'), (1, 'american'), (1, 'apart'), (1, 'appealed'), (1, 'applaudedthe'), (1, 'approached'), (1, 'army'), (1, 'balanced'), (1, 'bias'), (1, 'biasthe'), (1, 'binding'), (1, 'blunt'), (1, 'bridgedim'), (1, 'center'), (1, 'change'), (1, 'changed'), (1, 'city'), (1, 'clap'), (1, 'come'), (1, 'comfort'), (1, 'concerned'), (1, 'confess'), (1, 'consensus'), (1, 'console'), (1, 'correctness'), (1, 'country'), (1, 'course'), (1, 'criminal'), (1, 'cynicism'), (1, 'days'), (1, 'deaths'), (1, 'debate'), (1, 'demented'), (1, 'democracy'), (1, 'dismiss'), (1, 'divide'), (1, 'divided'), (1, 'divisions'), (1, 'doubt'), (1, 'earlier'), (1, 'earnest'), (1, 'effort'), (1, 'experience'), (1, 'experienced'), (1, 'exposed'), (1, 'family'), (1, 'far'), (1, 'fault'), (1, 'fear'), (1, 'fearful'), (1, 'feel'), (1, 'fighting'), (1, 'finding'), (1, 'forging'), (1, 'frustration'), (1, 'george'), (1, 'gospel'), (1, 'great'), (1, 'grew'), (1, 'griefstricken'), (1, 'grieves'), (1, 'grieving'), (1, 'gunned'), (1, 'hatred'), (1, 'heart'), (1, 'heroism'), (1, 'holdim'), (1, 'home'), (1, 'honest'), (1, 'hoping'), (1, 'house'), (1, 'huddled'), (1, 'im'), (1, 'implored'), (1, 'impossible'), (1, 'inherent'), (1, 'insist'), (1, 'john'), (1, 'josh'), (1, 'justice'), (1, 'killings'), (1, 'later'), (1, 'legacy'), (1, 'let'), (1, 'lifemr'), (1, 'like'), (1, 'limitations'), (1, 'line'), (1, 'listening'), (1, 'little'), (1, 'louisiana'), (1, 'man'), (1, 'mass'), (1, 'memorials'), (1, 'men'), (1, 'minnesotamr'), (1, 'month'), (1, 'mourned'), (1, 'nations'), (1, 'nave'), (1, 'odds'), (1, 'policing'), (1, 'political'), (1, 'poured'), (1, 'praise'), (1, 'presidency'), (1, 'presidencymr'), (1, 'press'), (1, 'pulling'), (1, 'questioned'), (1, 'quoted'), (1, 'reassure'), (1, 'recognizes'), (1, 'reject'), (1, 'remember'), (1, 'renew'), (1, 'reverse'), (1, 'row'), (1, 'saidbehind'), (1, 'saidi'), (1, 'second'), (1, 'secretary'), (1, 'seen'), (1, 'service'), (1, 'similar'), (1, 'simply'), (1, 'slaughter'), (1, 'sought'), (1, 'soul'), (1, 'speech'), (1, 'speeches'), (1, 'speechwriters'), (1, 'spoke'), (1, 'spoken'), (1, 'stronger'), (1, 'symptom'), (1, 'tensions'), (1, 'things'), (1, 'think'), (1, 'thisformer'), (1, 'times'), (1, 'today'), (1, 'togetherbut'), (1, 'truthmr'), (1, 'tuesday'), (1, 'understood'), (1, 'unity'), (1, 'valuesmr'), (1, 'veteran'), (1, 'w'), (1, 'week'), (1, 'weve'), (1, 'white'), (1, 'witnessed'), (1, 'worsening')]\n"
     ]
    }
   ],
   "source": [
    "#print ordered without stopwords\n",
    "print OrderWordBag(art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Well that's it. Now that you have bag or words in your tool box, go forth and bag yourself some documents to play with. Also, I recommend you look into <a href=\"http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html\">Tf-idf</a>, and <a href=\"https://turi.com/learn/userguide/feature-engineering/bm25.html\"> BM25 </a>. As always, happy exploring.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
